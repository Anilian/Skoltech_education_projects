{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605695a7",
   "metadata": {},
   "source": [
    "Суть задания в том, чтобы выкинуть ненужные картинки и заменить описание у нужных картинок, при его наличии.\n",
    "\n",
    "Изначально будет несколько архивов. В каждом архиве есть папка с фото, называется 0.tar, 1.tar и тд, к каждому такому тарнику будет идти цсвшка с описанием фотографий, называются аналогично 0.csv, 1.csv и так далее. 0й тарник соответствует нулевой цсвшке и далее по аналогии. Такие цсвшки назову основными.\n",
    "\n",
    "Также в архиве будут цсвшки с названием 0_new.csv, 1_new.csv и так далее. Это те же самые цсвшки, но в них подправлены описания и есть доп колонки. Такие цсвшки назову дополнительными\n",
    "\n",
    "Алгоритм:\n",
    "1. сначала нужно выкинуть из основных цсвшек те фотки, у которых в дополнительных в колонке query_flags стоит 1. в качестве ключа берите первую колонку image_name, это название самой фотки\n",
    "2. затем нужно заменить описания в основной цсвшке на описания из дополнительной для оставшихся фото. описания к фото записаны в колонке caption\n",
    "3. после этого на выходе вы получите несколько цсвшек, в которых исправленные описания и часть фото удалены. те фото, которых нет в цсвшках нужно удалить из самих архивов с фото\n",
    "4. теперь нужно пересобрать цсвшки и тарники так, чтобы там было по 1000 фотографий. только у последней цсвшки в списке и у последнего соответствующего ему тарника может быть меньше 1000 фоток. рекомендую к названию фото просто добавить номер папки, откуда это фото, в стиле 0.png станет 0_0.png, если это фото из нулевого тарника например. название самого фото меняем и название фото в цсвшке, соответственно\n",
    "5. результат залить на s3 или пинговать меня, дам диск куда лить\n",
    "\n",
    "Что может пойти не так и на что нужно обратить внимание:\n",
    "1) ребята-разметчики некоторые изнасиловали цсвшки и где-то в дополнительных цсвшках разделитель запятая, где-то точка с запятой, где-то флаг имеет тип строка, где-то инт, где-то флоат (вообще по умолчанию он был интом). придется немного посидеть над тем, чтобы все это корректно считать. если совсем никак - пингуйте меня\n",
    "2) перед тем как удалять строки из цсвшек или архивов - сделайте резервную копию или сделайте отдельно тестовый блок себе. мне будет проблематично вам еще раз данные отсылать или вам их снова качать\n",
    "3) когда вы делаете тарник (его можно сделать хоть консолькой) смотрите, чтобы он не создавал архив в архиве. то есть при разорхивации тарника 0.tar должны появляться сразу фото, а не папка 0, в которой уже лежат фото\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f39d246-515d-4886-9b8c-196dbea664cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tarfile\n",
    "import tarfile, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8952b-308b-47f7-800a-1d616f79a478",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac254c8-00ca-4c18-95bb-8c660f7b52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'C:/Users/annai/Filter_new_csv/data_30_59'\n",
    "dir_save = 'C:/Users/annai/Filter_new_csv/rename'\n",
    "\n",
    "shard_idx = 0\n",
    "\n",
    "file_data = str(shard_idx) + '.csv'\n",
    "new_data = str(shard_idx) + '_new.csv'\n",
    "\n",
    "csv_path = os.path.join(dir_name,file_data)\n",
    "new_data_path = os.path.join(dir_name,new_data)\n",
    "\n",
    "\n",
    "df = pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bef0cb2-020e-43c7-a13c-c3c91549ae5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>url</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>similarity</th>\n",
       "      <th>punsafe</th>\n",
       "      <th>pwatermark</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>Дуговой фрезерный нож резак для дерева фрезы б...</td>\n",
       "      <td>800</td>\n",
       "      <td>771</td>\n",
       "      <td>https://ae01.alicdn.com/kf/HTB1p6KqRFXXXXceXVX...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.264643</td>\n",
       "      <td>4.679442e-05</td>\n",
       "      <td>0.248935</td>\n",
       "      <td>720572426622240968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Баня на реке и на берегу реки: преимущества, н...</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "      <td>https://par-torg.com/wp-content/uploads/c/9/e/...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.266469</td>\n",
       "      <td>1.565069e-03</td>\n",
       "      <td>0.240798</td>\n",
       "      <td>-3561693715683967203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>\"\"\"Ульяновская область стала родиной Колобка  ...</td>\n",
       "      <td>960</td>\n",
       "      <td>720</td>\n",
       "      <td>https://ds02.infourok.ru/uploads/ex/090e/00000...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.278951</td>\n",
       "      <td>4.573132e-01</td>\n",
       "      <td>0.276760</td>\n",
       "      <td>-8368125490294308610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>замок зажигания уаз буханка: устройство, схема...</td>\n",
       "      <td>1280</td>\n",
       "      <td>720</td>\n",
       "      <td>https://nashikolesa.ru/wp-content/uploads/2020...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.278530</td>\n",
       "      <td>3.395230e-03</td>\n",
       "      <td>0.217097</td>\n",
       "      <td>-5736097797218125412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Открытый Сенсор светодиодный прожекторы IP65 1...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>https://ae01.alicdn.com/kf/HTB1J_dEJVXXXXa1XVX...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.288629</td>\n",
       "      <td>5.561715e-07</td>\n",
       "      <td>0.117737</td>\n",
       "      <td>-3381977850604610995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                            caption  width  \\\n",
       "0      0.jpg  Дуговой фрезерный нож резак для дерева фрезы б...    800   \n",
       "1      1.jpg  Баня на реке и на берегу реки: преимущества, н...   1280   \n",
       "2      2.jpg  \"\"\"Ульяновская область стала родиной Колобка  ...    960   \n",
       "3      3.jpg  замок зажигания уаз буханка: устройство, схема...   1280   \n",
       "4      4.jpg  Открытый Сенсор светодиодный прожекторы IP65 1...   1000   \n",
       "\n",
       "   height                                                url LANGUAGE  \\\n",
       "0     771  https://ae01.alicdn.com/kf/HTB1p6KqRFXXXXceXVX...       ru   \n",
       "1     853  https://par-torg.com/wp-content/uploads/c/9/e/...       ru   \n",
       "2     720  https://ds02.infourok.ru/uploads/ex/090e/00000...       ru   \n",
       "3     720  https://nashikolesa.ru/wp-content/uploads/2020...       ru   \n",
       "4    1000  https://ae01.alicdn.com/kf/HTB1J_dEJVXXXXa1XVX...       ru   \n",
       "\n",
       "   similarity       punsafe  pwatermark                 hash  \n",
       "0    0.264643  4.679442e-05    0.248935   720572426622240968  \n",
       "1    0.266469  1.565069e-03    0.240798 -3561693715683967203  \n",
       "2    0.278951  4.573132e-01    0.276760 -8368125490294308610  \n",
       "3    0.278530  3.395230e-03    0.217097 -5736097797218125412  \n",
       "4    0.288629  5.561715e-07    0.117737 -3381977850604610995  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3cfa3d1-6a1d-4f3e-a20e-0bdc43315bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_data = pd.read_csv(new_data_path, sep=';',encoding='cp1251', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f606dffb-70eb-4bde-b882-e66b31c68f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption</th>\n",
       "      <th>query_flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>Деревообрабатывающий дуговой фрезерный нож</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Баня плывёт по воде</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>\"\"\"Ульяновская область стала родиной Колобка \"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>Замок зажигания УАЗ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Чёрный настенный светодиодный прожектор</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                            caption  query_flags\n",
       "0      0.jpg         Деревообрабатывающий дуговой фрезерный нож            0\n",
       "1      1.jpg                                Баня плывёт по воде            0\n",
       "2      2.jpg  \"\"\"Ульяновская область стала родиной Колобка \"...            1\n",
       "3      3.jpg                                Замок зажигания УАЗ            0\n",
       "4      4.jpg           Чёрный настенный светодиодный прожектор             0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "667f7f02-862d-4963-9915-6943afb68103",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_idx_q = np.where(df_new_data['query_flags'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3fdab9de-e968-4240-81eb-1d866c009504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_idx_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e82cec95-443b-4e52-bcd6-342d52a1a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(df_new_data))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9d1dac72-4c5f-4a99-9edd-707fe9f82f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption</th>\n",
       "      <th>query_flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>4995.jpg</td>\n",
       "      <td>Книга театр теней Дюймовочка</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4996.jpg</td>\n",
       "      <td>Прозрачный больше сетка пластик в коробку милы...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4997.jpg</td>\n",
       "      <td>Djeco Музыкальный инструмент Крокодил06372Музы...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4998.jpg</td>\n",
       "      <td>Тетрациклиновые зубы – как избавиться от этой ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4999.jpg</td>\n",
       "      <td>Красивые шарики на день рождения для девочки 01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name                                            caption  query_flags\n",
       "995   4995.jpg                       Книга театр теней Дюймовочка            0\n",
       "996   4996.jpg  Прозрачный больше сетка пластик в коробку милы...            0\n",
       "997   4997.jpg  Djeco Музыкальный инструмент Крокодил06372Музы...            0\n",
       "998   4998.jpg  Тетрациклиновые зубы – как избавиться от этой ...            0\n",
       "999   4999.jpg    Красивые шарики на день рождения для девочки 01            0"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a799264-a38e-45ba-b329-3852a59af357",
   "metadata": {},
   "source": [
    "1. сначала нужно выкинуть из основных цсвшек те фотки, у которых в дополнительных в колонке query_flags стоит 1. в качестве ключа берите первую колонку image_name, это название самой фотки\n",
    "df_new_datanan_idx = np.where(df['column_name'].isnull())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "09b88cbe-cc52-4de0-9687-2d2be7fa863a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#получить индекс строки, где хотя бы одно значение NaN\n",
    "\n",
    "nan_idx_q = np.where(df_new_data['query_flags'].isnull())[0]\n",
    "nan_idx_c = np.where(df_new_data['caption'].isnull())[0]\n",
    "nan_idx_n = np.where(df_new_data['image_name'].isnull())[0]\n",
    "\n",
    "nan_idx_q = np.concatenate((nan_idx_q, nan_idx_c), axis=0)\n",
    "for value in nan_idx_n:\n",
    "    if value not in nan_idx_q:\n",
    "        nan_idx_q = np.concatenate((nan_idx_q, nan_idx_n), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ff5e1e61-d5a5-442b-b72b-42d55a5ab280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_idx_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f26f84f1-0573-4989-87d6-f4bc062155e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in nan_idx_q:\n",
    "    df_new_data.drop(idx,  axis=1,inplace=True)\n",
    "    \n",
    "for idx in nan_idx_q:\n",
    "    df.drop(idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "82b51579-f112-40d1-bf08-2cce1089333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "abdc5d65-8bfd-430a-b061-c4e116bedb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#датафрем с названием файла и его query_flags\n",
    "dict_flags = dict(zip(list(df_new_data.image_name), list(df_new_data.query_flags)))\n",
    "\n",
    "#список имен файлов для удаления\n",
    "list_delete = []\n",
    "for key,value in dict_flags.items():\n",
    "    if value ==1:\n",
    "        list_delete.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0d225887-4619-4ac5-8207-d6efcc323395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10006.jpg',\n",
       " '10015.jpg',\n",
       " '10016.jpg',\n",
       " '10019.jpg',\n",
       " '10024.jpg',\n",
       " '10025.jpg',\n",
       " '10031.jpg',\n",
       " '10035.jpg',\n",
       " '10036.jpg',\n",
       " '10045.jpg']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_delete[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0aab3e72-5df5-45d1-97bd-c0d9a969a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаление из главной таблицы строк, чьи изображения имеют query_flags==1\n",
    "for idx in list_delete:\n",
    "    index = df.index [df['image_name']== idx ].tolist()\n",
    "    df.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "67dd7368-2bea-47f9-970a-e67abc89e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаление из новой таблицы строк, чьи изображения имеют query_flags==1\n",
    "for idx in list_delete:\n",
    "    index = df_new_data.index [df_new_data['image_name']== idx ].tolist()\n",
    "    df_new_data.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "22457e1b-4d8e-498b-aac5-71e05efe13a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>url</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>similarity</th>\n",
       "      <th>punsafe</th>\n",
       "      <th>pwatermark</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>Продажа  дома п. Высокая Гора, ул Черноморская...</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>http://intrum11-29.intrumnet.com/files/crm/pro...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.293233</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.031824</td>\n",
       "      <td>8753873322058583918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.jpg</td>\n",
       "      <td>Купить 10652_plus size, Сарафан для девочек СМ...</td>\n",
       "      <td>1200</td>\n",
       "      <td>1600</td>\n",
       "      <td>https://main-cdn.sbermegamarket.ru/hlr-system/...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.266255</td>\n",
       "      <td>0.079889</td>\n",
       "      <td>0.304476</td>\n",
       "      <td>476272511972184164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002.jpg</td>\n",
       "      <td>В Астрахани состоится юбилейный гала-концерт ф...</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "      <td>https://folc.ru/wp-content/uploads/2018/11/IMG...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.292562</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>0.219494</td>\n",
       "      <td>6713797085172910306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003.jpg</td>\n",
       "      <td>Оформление аквариума, акваскейп</td>\n",
       "      <td>763</td>\n",
       "      <td>1024</td>\n",
       "      <td>https://i0.wp.com/praeclara.ru/wp-content/uplo...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.274981</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.229119</td>\n",
       "      <td>-1069998755039171206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>\"\"\"Керамическая ваза для цветов ручной работы ...</td>\n",
       "      <td>720</td>\n",
       "      <td>720</td>\n",
       "      <td>https://images.satu.kz/80068858_keramicheskaya...</td>\n",
       "      <td>ru</td>\n",
       "      <td>0.278370</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.167407</td>\n",
       "      <td>-1076175039013698791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                            caption  width  \\\n",
       "0  10000.jpg  Продажа  дома п. Высокая Гора, ул Черноморская...   1024   \n",
       "1  10001.jpg  Купить 10652_plus size, Сарафан для девочек СМ...   1200   \n",
       "2  10002.jpg  В Астрахани состоится юбилейный гала-концерт ф...   1280   \n",
       "3  10003.jpg                    Оформление аквариума, акваскейп    763   \n",
       "4  10004.jpg  \"\"\"Керамическая ваза для цветов ручной работы ...    720   \n",
       "\n",
       "   height                                                url LANGUAGE  \\\n",
       "0     768  http://intrum11-29.intrumnet.com/files/crm/pro...       ru   \n",
       "1    1600  https://main-cdn.sbermegamarket.ru/hlr-system/...       ru   \n",
       "2     853  https://folc.ru/wp-content/uploads/2018/11/IMG...       ru   \n",
       "3    1024  https://i0.wp.com/praeclara.ru/wp-content/uplo...       ru   \n",
       "4     720  https://images.satu.kz/80068858_keramicheskaya...       ru   \n",
       "\n",
       "   similarity   punsafe  pwatermark                 hash  \n",
       "0    0.293233  0.000334    0.031824  8753873322058583918  \n",
       "1    0.266255  0.079889    0.304476   476272511972184164  \n",
       "2    0.292562  0.815100    0.219494  6713797085172910306  \n",
       "3    0.274981  0.000753    0.229119 -1069998755039171206  \n",
       "4    0.278370  0.000036    0.167407 -1076175039013698791  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e9d9bded-c64f-413c-a4cb-eb1410c0664a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5bb9a702-4fff-42ec-ac7b-e3a73493dc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption</th>\n",
       "      <th>query_flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.jpg</td>\n",
       "      <td>Три кирпичных дома с забором и двумя соснами</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.jpg</td>\n",
       "      <td>девочка в сарафане и белой блузке с черной баб...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002.jpg</td>\n",
       "      <td>танчующие девочки  и мальчики в футболках \"я л...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003.jpg</td>\n",
       "      <td>зеленое растение в прозрачном аквариуме</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004.jpg</td>\n",
       "      <td>черно- фиолетовая ваза с цветами</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                            caption  query_flags\n",
       "0  10000.jpg      Три кирпичных дома с забором и двумя соснами             0\n",
       "1  10001.jpg  девочка в сарафане и белой блузке с черной баб...            0\n",
       "2  10002.jpg  танчующие девочки  и мальчики в футболках \"я л...            0\n",
       "3  10003.jpg           зеленое растение в прозрачном аквариуме             0\n",
       "4  10004.jpg                  черно- фиолетовая ваза с цветами             0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e85b62-0a83-4fbc-a258-4131c5970f6d",
   "metadata": {},
   "source": [
    "2. затем нужно заменить описания в основной цсвшке на описания из дополнительной для оставшихся фото. описания к фото записаны в колонке caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def5156-1ce6-466a-be30-3879e91d59af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_caption = dict(zip(list(df_new_data.image_name), list(df_new_data.caption)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aac49f-24cb-4787-8cb2-cee9ddda09c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1738605-7d22-4d67-843d-56aed3223f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(df.index):\n",
    "    line = df.loc[i]\n",
    "    for name,new_caption in dict_caption.items():\n",
    "        if line['image_name'] == name:\n",
    "            df.at[i,'caption'] = dict_caption[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927942d-4d36-40e0-915e-d4dbd735d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b96a58e-bf85-4a2a-b67a-15aff512593c",
   "metadata": {},
   "source": [
    "3. после этого на выходе вы получите несколько цсвшек, в которых исправленные описания и часть фото удалены. те фото, которых нет в цсвшках нужно удалить из самих архивов с фото"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bde5d6-0667-49fe-bcfa-0eecda98008d",
   "metadata": {},
   "source": [
    "рекомендую к названию фото просто добавить номер папки, откуда это фото, в стиле 0.png станет 0_0.png, если это фото из нулевого тарника например. название самого фото меняем и название фото в цсвшке, соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4ec90-f2d6-4907-b8c7-d136d477e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_jpg(x):\n",
    "    x = x[:-4] + '_' + str(shard_idx) + '.jpg'\n",
    "    return x\n",
    "\n",
    "df['image_name'] = df['image_name'].apply(rename_jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32857144-26c1-41d0-8156-87c3bbeb91e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c8cc8-6073-4b2c-a6a1-9a1ce1560292",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv_name = str(shard_idx) + '_new.csv'\n",
    "\n",
    "path_save = os.path.join(dir_save,new_csv_name)\n",
    "df.to_csv(path_save, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e182f-b21a-4771-b196-20a84e9c67f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_extr_path = 'C:/Users/annai/Practic/Filter_new_csv/tar_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33de3f2-14d6-45e0-9f71-e8ca381902f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_name = str(shard_idx) + '.tar'\n",
    "with tarfile.open(os.path.join(dir_name,tar_name)) as tar:\n",
    "    tar.extractall(tar_extr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e98be-753d-4cca-a430-be0aa0988c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_names = df['image_name'].to_list()\n",
    "for idx, name in enumerate(csv_names):\n",
    "    csv_names[idx]=name[:-4] + '_' + str(shard_idx) + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a73c51-5543-4a64-aee2-753f9d5bfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляем те файлы, которых нет в нашей таблице, а те, что есть переименовываем с указанием шарда\n",
    "count = 0\n",
    "for filename in os.listdir(tar_extr_path):\n",
    "    if '_' not in filename:\n",
    "        new_name = filename[:-4] + '_' + str(shard_idx) + '.jpg'\n",
    "        if new_name in csv_names:\n",
    "            os.rename(os.path.join(tar_extr_path, filename), os.path.join(tar_extr_path,new_name))\n",
    "        else:\n",
    "            os.remove(os.path.join(tar_extr_path, filename))  \n",
    "            \n",
    "            count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31799d-2d87-479d-af6a-e07de18a2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('delete {} images from {} shard'.format(count, shard_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5fce5-0e55-47ac-8496-50a81d4c499a",
   "metadata": {},
   "source": [
    "4. теперь нужно пересобрать цсвшки и тарники так, чтобы там было по 1000 фотографий. только у последней цсвшки в списке и у последнего соответствующего ему тарника может быть меньше 1000 фоток.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5c244-3724-4586-aebb-5d912bc8fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = 'C:/Users/annai/Filter_new_csv/rename/0_new.csv'\n",
    "csv_2 = 'C:/Users/annai/Filter_new_csv/rename/3_new.csv'\n",
    "csv_3 = 'C:/Users/annai/Filter_new_csv/rename/4_new.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072753e-c76d-45ed-9804-672066fa05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_1 = pd.read_csv(csv_1)\n",
    "csv_2 = pd.read_csv(csv_2)\n",
    "csv_3 = pd.read_csv(csv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486feb2-6614-4ae0-9bb8-1a45355a0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29c609-538f-4b4f-8a16-871402acd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4562f3-c17e-4849-9ac9-27a4f431bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8256918-4f23-42ce-99fa-c19c850f7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "itog_csv = {}\n",
    "iter_sum = 0\n",
    "\n",
    "for csv_name in filename:\n",
    "    csv_df = pd.read_csv(os.path.join(dir_save,csv_name))\n",
    "    \n",
    "    if iter_sum + len(csv_df) < 1000:\n",
    "        iter_sum = iter_sum + len(csv_df)\n",
    "        itog_csv[csv_name] = len(csv_df)\n",
    "    else:\n",
    "        delta = 1000 - iter_sum\n",
    "        itog_csv[csv_name] = delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65e3ba-d370-4e62-b981-bc8d3e070c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "itog_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4f071-b976-4f27-8ec4-75b6dfa60639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new final csv with merge other dataframe\n",
    "i = 0\n",
    "for k,v in itog_csv.items():\n",
    "    i += 1\n",
    "    data_i = pd.read_csv(os.path.join(dir_save,k))\n",
    "    data_i = data_i.iloc[:v]\n",
    "    if i==1:\n",
    "        concate_data = data_i\n",
    "    else:\n",
    "        concate_data = pd.concat([concate_data,data_i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef797b0-0a22-4b6e-88f5-0c6edc579b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_shard = 0\n",
    "final_csv_name = str(final_shard) + '_final.csv'\n",
    "final_path_save = os.path.join(dir_save,final_csv_name)\n",
    "concate_data.to_csv(final_path_save, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318225b-deeb-4c64-8f00-bd7e1bda35ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdd981-33a1-4c4e-9da5-1dd47226eec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001752a-dddf-47b0-ace5-5547e69e8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tar(img_path, tar_path,concate_data)\n",
    "    csv_names = concate_data['image_name'].to_list()\n",
    "    os.chdir('C:/Users/annai/Filter_new_csv/tar_file')\n",
    "\n",
    "    arc_name = str(0) + '.tar'\n",
    "    tar_export = 'C:/Users/annai/Filter_new_csv'\n",
    "    fp=tarfile.open(os.path.join(tar_export, arc_name), mode='w')\n",
    "    try: \n",
    "        for file in glob.glob('*.*'):\n",
    "            if file in csv_names:\n",
    "                fp.add(file)\n",
    "    finally:\n",
    "        fp.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fdd13a-ca1e-4c54-bc76-153c4b6ad304",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ca5dbd1-1c23-4f8d-811e-0f27921b1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(idx, dir_name): #по индексу получить датафремы для главной таблицы и новой\n",
    "    # print(idx)\n",
    "    file_data = str(idx) + '.csv'\n",
    "    new_data = str(idx) + '_new.csv'\n",
    "    csv_path = os.path.join(dir_name,file_data)\n",
    "    new_data_path = os.path.join(dir_name,new_data)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(new_data_path)\n",
    "    if idx == str(21):\n",
    "        # print('cheak 21')\n",
    "        # df_new_data = pd.read_csv(new_data_path, sep=';',encoding='cp1251', on_bad_lines='skip') #30-59 shard for 0\n",
    "        df_new_data = pd.read_csv(new_data_path, sep = ';', on_bad_lines='skip')  \n",
    "    else:\n",
    "        df_new_data = pd.read_csv(new_data_path, sep = ',', on_bad_lines='skip')\n",
    "    return df, df_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcc2d443-a82a-454a-bf25-40ab43d3f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_nan(df_new_data): #получить индекс строки, где хотя бы одно значение NaN\n",
    "    \n",
    "    nan_idx_q = np.where(df_new_data['query_flags'].isnull())[0]\n",
    "    nan_idx_c = np.where(df_new_data['caption'].isnull())[0]\n",
    "    nan_idx_n = np.where(df_new_data['image_name'].isnull())[0]\n",
    "\n",
    "    nan_idx_q = np.concatenate((nan_idx_q, nan_idx_c), axis=0)\n",
    "    for value in nan_idx_n:\n",
    "        if value not in nan_idx_q:\n",
    "            nan_idx_q = np.concatenate((nan_idx_q, nan_idx_n), axis=0)\n",
    "    return nan_idx_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8efd32e-cd31-4822-a15b-ce8dd988166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_from_df(list_delete, df):#удаление из главной таблицы строк, чьи изображения имеют query_flags==1\n",
    "    for idx in list_delete:\n",
    "        index = df.index [df['image_name']== idx ].tolist()\n",
    "        df.drop(index, inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86591991-8694-4f7d-8394-ce3f86bb3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_jpg(x):\n",
    "    x = x[:-4] + '_' + str(shard_idx) + '.jpg'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1001a24c-3428-4dcb-9420-a7a62aa4165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_caption(x):\n",
    "#     x = x[:-4] + '_' + str(shard_idx) + '.jpg'\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21afe300-0eea-4982-9ed7-1f66c79d92e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_preproces(index,dir_name):\n",
    "    \n",
    "    #по индексу получить датафремы для главной таблицы и новой\n",
    "    df, df_new_data = get_df(index, dir_name)\n",
    "    #получить индекс строки, где хотя бы одно значение NaN\n",
    "    nan_idx= idx_nan(df_new_data)\n",
    "\n",
    "    #выбросить эти строки из основной и новой таблицы,чтобы не мешались\n",
    "    for idx in nan_idx:\n",
    "        df_new_data.drop(idx, inplace=True)\n",
    "    for idx in nan_idx:\n",
    "        df.drop(idx, inplace=True)\n",
    "\n",
    "    #датафрем с названием файла и его query_flags\n",
    "    dict_flags = dict(zip(list(df_new_data.image_name), list(df_new_data.query_flags)))\n",
    "    #список имен файлов для удаления\n",
    "    list_delete = []\n",
    "    for key,value in dict_flags.items():\n",
    "        if value ==1:\n",
    "            list_delete.append(key)\n",
    "\n",
    "    #удаление из  таблицы строк, чьи изображения имеют query_flags==1\n",
    "    df = del_from_df(list_delete, df)\n",
    "    df_new_data = del_from_df(list_delete, df_new_data)\n",
    "\n",
    "    #датафрем с названием файла и его caption\n",
    "    dict_caption = dict(zip(list(df_new_data.image_name), list(df_new_data.caption)))\n",
    "    # замена caption в главной таблице\n",
    "    for i in list(df.index):\n",
    "        line = df.loc[i]\n",
    "        for name,new_caption in dict_caption.items():\n",
    "            if line['image_name'] == name:\n",
    "                df.at[i,'caption'] = dict_caption[name]\n",
    "    #замена названия файла с учетом номера оригинального шарда\n",
    "    df['image_name'] = df['image_name'].apply(rename_jpg)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9856f9c0-b00b-4181-94da-84f9d0d12258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_jpg(tar_extr_path, df, shard_idx): #удаляем те файлы, которых нет в нашей таблице, а те, что есть переименовываем с указанием шарда\n",
    "    \n",
    "    #получаем список имен из главной таблицы\n",
    "    csv_names = df['image_name'].to_list()\n",
    "    count = 0\n",
    "    #сравниваем каждый файл в папке со списком нужных имен из csv\n",
    "    for filename in os.listdir(tar_extr_path):\n",
    "        if '_' not in filename: #если нет '_' значит, это только что разархивированные фото\n",
    "            new_name = filename[:-4] + '_' + str(shard_idx) + '.jpg'\n",
    "            if new_name in csv_names:\n",
    "                os.rename(os.path.join(tar_extr_path, filename), os.path.join(tar_extr_path,new_name))\n",
    "            else:\n",
    "                os.remove(os.path.join(tar_extr_path, filename))  \n",
    "                count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2584de03-dd40-4fd2-86b3-8ea366ee8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv(index_new_df, dir_save, delta, past_delta): #объединить уже существующие таблицы\n",
    "    \n",
    "    #delta = filies_count - 1000 \n",
    "    itog_csv = {}\n",
    "    iter_sum = 0\n",
    "    last_csv = index_new_df[-1]\n",
    "    first_csv = index_new_df[0]\n",
    "    \n",
    "    if past_delta ==0:\n",
    "        for i in index_new_df:\n",
    "            csv_name = str(i) + '_update.csv'\n",
    "            path_save = os.path.join(dir_save,csv_name)\n",
    "            csv_df = pd.read_csv(path_save)\n",
    "            if i != last_csv:\n",
    "                itog_csv[csv_name] = len(csv_df)\n",
    "            else:\n",
    "                itog_csv[csv_name] = len(csv_df) - delta\n",
    "                \n",
    "    else:\n",
    "          for i in index_new_df:\n",
    "            csv_name = str(i) + '_update.csv'\n",
    "            path_save = os.path.join(dir_save,csv_name)\n",
    "            csv_df = pd.read_csv(path_save)\n",
    "            \n",
    "            if i == first_csv:\n",
    "                itog_csv[csv_name] = past_delta\n",
    "            elif i != last_csv:\n",
    "                itog_csv[csv_name] = len(csv_df)\n",
    "            else:\n",
    "                itog_csv[csv_name] = len(csv_df) - delta       \n",
    "    print(itog_csv)\n",
    "\n",
    "    first_folder_csv = '0_update.csv'\n",
    "    # create new final csv with merge other dataframe\n",
    "    i = 0\n",
    "    dict_len = len(itog_csv)\n",
    "    for k,v in itog_csv.items():\n",
    "        # print(i)\n",
    "        # print(k)\n",
    "\n",
    "        if delta != 0:\n",
    "            if k == first_folder_csv: #когда первая таблица из архива\n",
    "                # print('первая таблица из архива. start_value = 0')\n",
    "                data_i = pd.read_csv(os.path.join(dir_save,k))\n",
    "                data_split = data_i.iloc[0:v]\n",
    "                # print(len(data_split))\n",
    "                # data_split.to_csv('C:/Users/annai/Practic/Filter_new_csv/test0.csv', index=False)\n",
    "                concate_data = data_split\n",
    "                i += 1\n",
    "                # print('------------------')\n",
    "            \n",
    "            elif i==0: #когда начинается с остатка\n",
    "                \n",
    "                # print('start_value = delta')\n",
    "                data_i = pd.read_csv(os.path.join(dir_save,k))\n",
    "                data_split = data_i.iloc[len(data_i) - past_delta:len(data_i) - past_delta+v]\n",
    "                # print(len(data_split))\n",
    "                # data_split.to_csv('C:/Users/annai/Practic/Filter_new_csv/test10_2.csv', index=False)\n",
    "                concate_data = data_split\n",
    "                i += 1\n",
    "                # print('------------------')\n",
    "                      \n",
    "            else:\n",
    "                # print('start_value = 0')\n",
    "                data_i = pd.read_csv(os.path.join(dir_save,k))\n",
    "                data_split = data_i.iloc[0:v]\n",
    "                # print(len(data_split))\n",
    "                # data_split.to_csv('C:/Users/annai/Practic/Filter_new_csv/test10_1.csv', index=False)\n",
    "                i += 1\n",
    "                concate_data = pd.concat([concate_data,data_split])\n",
    "                # print('------------------')\n",
    "        else:\n",
    "            # print('нет остатка. Таблицы полностью. start_value = 0')\n",
    "            data_i = pd.read_csv(os.path.join(dir_save,k))\n",
    "            data_0 = data_i.iloc[0:v]\n",
    "            # data_0.to_csv('C:/Users/annai/Practic/Filter_new_csv/test10_1.csv', index=False)\n",
    "            i += 1\n",
    "            # print('------------------')\n",
    "    \n",
    "    return concate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5744e6b-617f-4526-8662-0d695f45389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tar(img_path, tar_path,concate_data, final_idx):\n",
    "    csv_names = concate_data['image_name'].to_list()\n",
    "    os.chdir(img_path)\n",
    "\n",
    "    tar_name = str(final_idx) + '.tar'\n",
    "    tar_path = os.path.join(tar_path, tar_name)\n",
    "    fp=tarfile.open(tar_path, mode='w')\n",
    "    try: \n",
    "        for file in glob.glob('*.*'):\n",
    "            if file in csv_names:\n",
    "                fp.add(file)\n",
    "    finally:\n",
    "        fp.close()\n",
    "        \n",
    "    print('export new tar', tar_path) \n",
    "    shutil.move(tar_path, 'C:/Users/annai/Practic/Filter_new_csv')\n",
    "    \n",
    "    #удалить эти файлы, чтобы не мешались\n",
    "    for file in (os.listdir(img_path)):\n",
    "        if file in csv_names:\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a975ebd-6557-4390-a3dd-a4e53c76498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.csv', '0.tar', '0_new.csv', '1.csv', '1.tar', '10.csv', '10.tar', '10_new.csv', '11.csv', '11.tar', '11_new.csv', '12.csv', '12.tar', '12_new.csv', '13.csv', '13.tar', '13_new.csv', '14.csv', '14.tar', '14_new.csv', '15.csv', '15.tar', '16.csv', '16.tar', '16_new.csv', '17.csv', '17.tar', '17_new.csv', '18.csv', '18.tar', '18_new.csv', '19.csv', '19.tar', '2.csv', '2.tar', '20.csv', '20.tar', '21.csv', '21.tar', '21_new.csv', '22.csv', '22.tar', '22_new.csv', '23.csv', '23.tar', '23_new.csv', '24.csv', '24.tar', '24_new.csv', '25.csv', '25.tar', '26.csv', '26.tar', '27.csv', '27.tar', '27_new.csv', '28.csv', '28.tar', '28_new.csv', '29.csv', '29.tar', '29_new.csv', '3.csv', '3.tar', '30.csv', '30.tar', '30_new.csv', '4.csv', '4.tar', '4_new.csv', '5.csv', '5.tar', '5_new.csv', '6.csv', '6.tar', '6_new.csv', '7.csv', '7.tar', '7_new.csv', '8.csv', '8.tar', '8_new.csv', '9.csv', '9.tar', '9_new.csv']\n"
     ]
    }
   ],
   "source": [
    "filename = os.listdir(dir_name)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433eb471-6203-4048-b7b9-e630c57b701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_idx = 0\n",
    "dir_name = 'C:/Users/annai/Filter_new_csv/laion_data_0_29'\n",
    "dir_save = 'C:/Users/annai/Filter_new_csv/rename'\n",
    "tar_extr_path = 'C:/Users/annai/Filter_new_csv/tar_file'\n",
    "\n",
    "filename = os.listdir(dir_name)\n",
    "#iter_sum = 0 #для проверки кол-ва файлов для отправки в s3\n",
    "index_new_df = []\n",
    "past_delta = 0\n",
    "\n",
    "for i, name in enumerate(filename):\n",
    "    if '.csv' in name:\n",
    "        if 'new' not in name:\n",
    "            print('choose new csv:', name)\n",
    "            shard_idx = name.split('.')[0]\n",
    "            csv_new_name = shard_idx + '_new.csv'\n",
    "            if csv_new_name in filename:\n",
    "                print('у этого шарда есть new_csv')\n",
    "                #получить обновленную таблицу с учетом новых данных\n",
    "                df_i = df_preproces(shard_idx,dir_name) \n",
    "                index_new_df.append(shard_idx)\n",
    "                \n",
    "                #и сохраняем\n",
    "                new_csv_name = str(shard_idx) + '_update.csv'\n",
    "                path_csv_save = os.path.join(dir_save,new_csv_name)\n",
    "                df_i.to_csv(path_csv_save, index=False)\n",
    "                print('shard_idx', shard_idx)\n",
    "                #разархивировать\n",
    "                tar_name = str(shard_idx) + '.tar'\n",
    "                print('tar_name', tar_name)\n",
    "                with tarfile.open(os.path.join(dir_name,tar_name)) as tar:\n",
    "                    tar.extractall(tar_extr_path)\n",
    "                #удаляем те файлы, которых нет в нашей таблице, а те, что есть переименовываем с указанием шарда    \n",
    "                count = delete_jpg(tar_extr_path,df_i,shard_idx)\n",
    "                \n",
    "            else:\n",
    "                print('у этого шарда нет new_csv')\n",
    "                if shard_idx not in index_new_df:\n",
    "                    index_new_df.append(shard_idx)\n",
    "                    csv_path = os.path.join(dir_name,name)\n",
    "                    df_i = pd.read_csv(csv_path, sep = ',', on_bad_lines='skip')\n",
    "                    df_i= df_i.dropna()\n",
    "                    #замена названия файла с учетом номера оригинального шарда\n",
    "                    df_i['image_name'] = df_i['image_name'].apply(rename_jpg)\n",
    "                    \n",
    "                    #и сохраняем\n",
    "                    new_csv_name = str(shard_idx) + '_update.csv'\n",
    "                    path_csv_save = os.path.join(dir_save,new_csv_name)\n",
    "                    df_i.to_csv(path_csv_save, index=False)\n",
    "                    print('shard_idx', shard_idx)\n",
    "                    #разархивировать\n",
    "                    tar_name = str(shard_idx) + '.tar'\n",
    "                    print('tar_name', tar_name)\n",
    "                    with tarfile.open(os.path.join(dir_name,tar_name)) as tar:\n",
    "                        tar.extractall(tar_extr_path)\n",
    "                        \n",
    "                    #сравниваем каждый файл в папке со списком нужных имен из csv\n",
    "                    for filename in os.listdir(tar_extr_path):\n",
    "                        if '_' not in filename: #если нет '_' значит, это только что разархивированные фото\n",
    "                            new_name = filename[:-4] + '_' + str(shard_idx) + '.jpg'\n",
    "                            os.rename(os.path.join(tar_extr_path, filename), os.path.join(tar_extr_path,new_name))\n",
    "\n",
    "            #получаем кол-во результирующих файлов для отправки в s3\n",
    "            shard_idx = len(os.listdir(tar_extr_path))\n",
    "            print('проверяем кол-во вайлов в папке',shard_idx )\n",
    "            if shard_idx > 1000:\n",
    "                print('стало > 1000')\n",
    "                print(index_new_df)\n",
    "                #объединить уже существующие таблицы\n",
    "                delta = shard_idx - 1000\n",
    "                concate_data = merge_csv(index_new_df, dir_save, delta, past_delta)\n",
    "                past_delta = delta\n",
    "                last = index_new_df[-1] #сохраняем только последнюю таблицу, тк из нее не все файлы были взяты\n",
    "                index_new_df = []\n",
    "                index_new_df.append(last)\n",
    "\n",
    "                #сохранить эту таблицу\n",
    "                final_csv_name = str(final_idx) + '_final.csv'\n",
    "                final_path_save = os.path.join(dir_save,final_csv_name)\n",
    "                concate_data.to_csv(final_path_save, index=False)\n",
    "                print('export final csv', final_path_save)\n",
    "                #получаем список имен из новой таблицы\n",
    "                csv_names = concate_data['image_name'].to_list()\n",
    "                #используя его, архивируем 1000 изображений\n",
    "                tar_path = 'C:/Users/annai/Practic/Filter_new_csv/tar_file'\n",
    "                create_tar(tar_extr_path, tar_path,concate_data, final_idx )\n",
    "                final_idx += 1\n",
    "                print('---------------------------')     \n",
    "            else:\n",
    "                print('все еще < 1000')\n",
    "                print('---------------------------')\n",
    "                continue\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "065f3460-bd86-44bb-a009-8ce7be44fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# работа с остатком фото\n",
    "idx = 9\n",
    "file_data = str(idx) + '_update.csv'\n",
    "csv_path = os.path.join(dir_save,file_data)\n",
    "df = pd.read_csv(csv_path)\n",
    " #получаем список имен из главной таблицы\n",
    "csv_names = df['image_name'].to_list()\n",
    "count = 0\n",
    "#сравниваем каждый файл в папке со списком нужных имен из csv\n",
    "for filename in os.listdir(tar_extr_path):\n",
    "        if new_name in csv_names:\n",
    "            continue\n",
    "        else:\n",
    "            os.remove(os.path.join(tar_extr_path, filename))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f42f57-8694-4321-b97a-d7c9650361c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_idx = 29\n",
    "tar_name = str(final_idx) + '.tar'\n",
    "tar_path = os.path.join(tar_path, tar_name)\n",
    "fp=tarfile.open(tar_path, mode='w')\n",
    "try: \n",
    "    for file in glob.glob('*.*'):\n",
    "        if file in csv_names:\n",
    "            fp.add(file)\n",
    "finally:\n",
    "    fp.close()\n",
    "\n",
    "print('export new tar', tar_path) \n",
    "shutil.move(tar_path, 'C:/Users/annai/_Practic/Filter_new_csv')\n",
    "\n",
    "#удалить эти файлы, чтобы не мешались\n",
    "for file in (os.listdir(tar_extr_path)):\n",
    "    if file in csv_names:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97749830-2edc-4467-9bfc-99627242a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = pd.read_csv(os.path.join(dir_save,file_data))\n",
    "v = 158\n",
    "data_split = data_i.iloc[v:len(data_i)]\n",
    "#сохранить эту таблицу\n",
    "final_csv_name = str(final_idx) + '_final.csv'\n",
    "final_path_save = os.path.join(dir_save,final_csv_name)\n",
    "data_split.to_csv(final_path_save, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b367c-ec27-40ef-b36d-32dd0a589e69",
   "metadata": {},
   "source": [
    "## Upload to S3import io\n",
    "import re\n",
    "import tarfile\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "182ab4c1-f7be-4abc-a805-7729221eb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import tarfile\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "34a37851-532b-4361-bac1-565f5e7442aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'officecds-bucket01'\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id='',\n",
    "    aws_secret_access_key='',\n",
    "    endpoint_url=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bfc26-1988-4582-8e57-5f7051cd5836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload csv\n",
    "csv_path = 'C:/Users/annai/Filter_new_csv/rename'\n",
    "for name in (os.listdir(csv_path)):\n",
    "    if 'final.csv' in name:\n",
    "        path = os.path.join(csv_path, name)\n",
    "        print(path)\n",
    "        path_upload = '/datasets_v3/text_image/rus_tematic/laion_data_0_59/shard_filter/' + name\n",
    "        print(path_upload)\n",
    "        with open(path,'rb') as f:\n",
    "            s3.upload_fileobj(f, BUCKET_NAME, path_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384df27e-6b29-4b5e-a8e0-f71c750b9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload tar\n",
    "path = 'C:/Users/annai/Filter_new_csv/'\n",
    "tar_list = []\n",
    "for name in (os.listdir(path)):\n",
    "    if '.tar' in name:\n",
    "        tar_list.append(name)\n",
    "        \n",
    "for name in tar_list:\n",
    "    path2 = path + name\n",
    "    path_upload = '/datasets_v3/text_image/rus_tematic/data_0_59/shard_filter/' + name\n",
    "    print(path_upload)\n",
    "    with open(path,'rb') as tar:\n",
    "        s3.upload_fileobj(tar, BUCKET_NAME, path_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "129bd5eb-6b67-4c95-8f2f-bf2870e2ee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,29):\n",
    "    name = str(i) +'.tar'\n",
    "    path = 'C:/Users/annai/Practic/Filter_new_csv/' + name\n",
    "    path_upload = '/datasets_v3/text_image/rus_tematic/laion_data_0_59/shard_filter/' + name\n",
    "    with open(path,'rb') as tar:\n",
    "        s3.upload_fileobj(tar, BUCKET_NAME, path_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61e318-5c17-4d5b-ac03-426ed97fba4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
